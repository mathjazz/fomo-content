#
msgid ""
msgstr ""
"POT-Creation-Date: 2021-07-15 08:21:27.371385+00:00\n"
"PO-Revision-Date: 2021-08-19 08:46+0000\n"
"Last-Translator: Théo Chevalier <theo.chevalier11@gmail.com>\n"
"Language: de\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 648d6281-cb81-4462-9c77-a625be8823a2\n"

msgctxt "title"
msgid "Apple Air Pods &amp; Air Pods Pro"
msgstr "Apple Air Pods & Air Pods Pro"

msgctxt "blurb"
msgid ""
"Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Whether you get the AirPods, AirPods Pro, or the"
" pricey AirPods Max, Apple has a pretty good record when it comes to privacy and security so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
msgstr ""

msgctxt "worst_case"
msgid ""
"Apple does a pretty good job with privacy and security as a company. They say they don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with "
"you, which is great. Apple did face backlash in 2019 when it came to light their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice "
"assistant's recordings. Apple changed their policy so users weren't automatically opted-in to human voice review. Recently, Apple made another <a id=\"a1\">positive change</a> for your Siri voice "
"requests — many audio requests for things like setting timers or alarms or controlling music will no longer be sent over the internet to their servers, instead processing them directly on the "
"device. This is better for your privacy."
msgstr ""

msgctxt "worst_case"
msgid ""
"Apple did recently suffer a bad <a id=\"a1\">security vulnerability</a> that resulted in spyware that could allow bad actors to record calls and messages and even turn an iPhone or iPad camera and "
"microphone on without the user knowing. Apple did patch the security vulnerability. This is a good reminder that even the best companies can be vulnerable to high level hacking."
msgstr ""

msgctxt "worst_case"
msgid ""
"All in all, your AirPods are probably pretty secure and private. They’re still super easy to lose though, so keep in mind you can turn the <a id=\"a1\">Find My</a> features on. That just means a "
"little more location tracking in your life, which, in this case might be worth it."
msgstr ""

msgctxt "signup_requirement_explanation"
msgid "No sign-up required"
msgstr ""

msgctxt "how_does_it_use_data_collected"
msgid ""
"Apple says it does not share your data with third parties for commercial or marketing purposes. In June 2021, Apple <a id=\"a1\">announced</a> that it will no longer send Siri requests to its "
"servers, but instead will process them at the device level."
msgstr ""

msgctxt "user_friendly_privacy_policy_helptext"
msgid ""
"Apple has a webpage highlighting its privacy principles and features. Apple begins its privacy policy with a statement of principles. While this statement is very long, it is clearly broken out into"
" relevant topics."
msgstr ""

msgctxt "strong_password_helptext"
msgid "Bluetooth required"
msgstr ""

msgctxt "manage_vulnerabilities_helptext"
msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. <a id=\"a1\">https://developer.apple.com/security-bounty/</a>"
msgstr ""

msgctxt "tips_to_protect_yourself"
msgid "You can say “Hey Siri, stop listening.” to turn off speech recognition for some time"
msgstr ""

msgctxt "personal_data_collected"
msgid "Name, email, phone number, address"
msgstr "Name, E-Mail, Telefonnummer, Adresse"

msgctxt "biometric_data_collected"
msgid "Voice recordings, if you opt-in"
msgstr "Sprachaufnahmen, wenn Sie zustimmen"

msgctxt "how_can_you_control_your_data"
msgid ""
"Apple retains personal data only for so long as necessary to fulfill the purposes for which it was collected, including as described in their Privacy Policy or in their service-specific privacy "
"notices, or as required by law. No specific data retention details are provided."
msgstr ""

msgctxt "track_record_details"
msgid ""
"Apple had a recent serious security vulnerability. From <a id=\"a1\">Firewall Times</a>: \"In September 2021, researchers discovered that a spyware called Pegasus had infected iPhones and other "
"Apple Devices via a ‘zero click exploit’, granting the spyware broad power over a users’ device. Once infected, the spyware could record calls and messages and even turn the device camera and "
"microphone on without the user knowing. Pegasus was produced by the NSO Group, an Israel-based company that sells its spyware to governments such as Mexico and Saudi Arabia. Though this spyware "
"would presumably be used to surveil terrorists and criminal enterprises, these governments have also used it to spy on activists, politicians, and journalists. As of September 13, 2021, Apple has "
"patched the exploit."
msgstr ""

msgctxt "ai_helptext"
msgid "Some of Apple's AI research can be found at <a id=\"a1\">https://machinelearning.apple.com/</a>."
msgstr ""

msgctxt "ai_what_can_it_do"
msgid ""
"Apple states in its privacy policy, \"Apple does not take any decisions involving the use of algorithms or profiling that significantly affect you.\" Apple employs machine learning in many different"
" ways, from using it to to improve Siri to using it to sharpen the photos that you take."
msgstr ""

#~ msgctxt "blurb"
#~ msgid ""
#~ "Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Fortunately, Apple has a pretty good record when"
#~ " it comes to privacy and security though so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
#~ msgstr ""
#~ "Sie gehören in die Ohren, sind immer an, immer verbunden und hören immer zu. Klingt, als ob da was schiefgehen könnte? Glücklicherweise hat Apple in der Vergangenheit gezeigt, dass Datenschutz und "
#~ "Sicherheit ernst genommen werden. Sie können also beruhigt sein. Jetzt müssen Sie nur noch herausfinden, wie Sie diese hübschen kleinen Pods nicht verlieren."

#~ msgctxt "worst_case"
#~ msgid ""
#~ "Apple does a good job with privacy and security as a company. They don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with you. Apple did "
#~ "face backlash in 2019 when it came to light that their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice assistant's recordings. Apple"
#~ " changed their policy so users weren't automatically opted-in to human voice review. Good work Apple!"
#~ msgstr ""
#~ "Apple leistet im Hinblick auf Datenschutz und Sicherheit gute Arbeit. Ihre Daten werden nicht weitergegeben oder verkauft, und Apple achtet besonders darauf, dass Ihre Siri-Anfragen nicht mit Ihnen "
#~ "in Verbindung gebracht werden. Trotzdem sah Apple sich 2019 mit einer Gegenreaktion konfrontiert, als ans Licht kam, dass Auftragnehmer regelmäßig vertrauliche persönliche Gespräche mithörten, "
#~ "während sie die Aufnahmen des Sprachassistenten überprüften. Apple änderte seine Richtlinien, sodass die Überprüfung von Sprachaufnahmen durch Menschen nicht automatisch eingeschaltet war. Gut "
#~ "gemacht, Apple!"

#~ msgctxt "how_does_it_use_data_collected"
#~ msgid ""
#~ "Apple does not share your data with third parties for commercial or marketing purposes. All of your Siri voice requests are associated to a random identifier, and if you have opted-in to allow Apple"
#~ " to have Voice recordings, Apple disassociates them after 6 months.  Apple does not share data with third parties for commercial or marketing purposes."
#~ msgstr ""
#~ "Apple gibt Ihre Daten nicht zu Werbe- oder Marketingzwecken an Dritte weiter. Alle über Siri getätigten Sprachbefehle werden einer zufälligen Kennung zugeteilt, und wenn Sie Apple Zugriff auf Ihre "
#~ "Sprachaufnahmen gewährt haben, wird die Verbindung zu Ihnen nach sechs Monaten unkenntlich gemacht.  Apple gibt keine Daten zu Werbe- oder Marketingzwecken an Dritte weiter."

#~ msgctxt "uses_encryption_helptext"
#~ msgid ""
#~ "Uses encryption in transit and at rest. After Apple recognizes the words “Hey Siri,” what you say is encrypted and associated with a random identifier without being tied to your Apple ID. Audio "
#~ "samples are only retained if you have opted-in."
#~ msgstr ""
#~ "Nutzt in Transit und Ruhezustand Verschlüsselung. Nach der Ansprache „Hey Siri“, die von Apple erkannt wird, ist alles, was Sie sagen, verschlüsselt und wird mit einem zufälligen Identifikator "
#~ "verknüpft, ohne mit Ihrer Apple ID in Verbindung gebracht zu werden. Audiosamples werden nur gespeichert, wenn Sie Ihre Zustimmung erteilt haben."

#~ msgctxt "strong_password_helptext"
#~ msgid "The device pairs securely via Bluetooth, which does not require a password."
#~ msgstr "Das Gerät verbindet sich sicher über Bluetooth und es wird kein Passwort benötigt."

#~ msgctxt "manage_vulnerabilities_helptext"
#~ msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. https://developer.apple.com/security-bounty/"
#~ msgstr ""
#~ "Apple hat ein Bug-Bounty-Programm, was bedeutet, dass jeder, der eine Sicherheitslücke entdeckt und diese verantwortungsvoll meldet, dafür bezahlt werden kann. https://developer.apple.com/security-"
#~ "bounty/"

#~ msgctxt "how_can_you_control_your_data"
#~ msgid "You can request that data be deleted. You can go to https://privacy.apple.com/ to get a copy of your data, correct your data, or delete your account."
#~ msgstr "Sie können die Löschung Ihrer Daten beantragen. Auf https://privacy.apple.com/ können Sie eine Kopie Ihrer Daten einholen, Ihre Daten korrigieren oder Ihr Konto löschen."

#~ msgctxt "track_record_details"
#~ msgid ""
#~ "They actually changed their Siri voice recording review practices—from an opt out to an opt-in—when people told them they were unhappy having contractors listen to the recordings. Good for them!"
#~ msgstr ""
#~ "Die Vorgehensweisen für die Prüfung von Sprachaufnahmen über Siri wurden geändert, nachdem Verbraucher geäußert hatten, dass sie nicht damit einverstanden waren, dass Vertragspartner mithören "
#~ "konnten. Seitdem müssen Verbraucher solchen Prüfungen aktiv zustimmen, statt sich aktiv dagegen auszusprechen. Gut gemacht!"

#~ msgctxt "ai_helptext"
#~ msgid ""
#~ "Apple employs machine learning in many different ways, from using it to to improve Siri to using it to sharpen the photos that you take. Apple states in its privacy policy, \"Apple does not take any"
#~ " decisions involving the use of algorithms or profiling that significantly affect you.\" Some of its research can be found at https://machinelearning.apple.com/."
#~ msgstr ""
#~ "Apple nutzt KI auf viele unterschiedliche Arten. Beispielsweise wird KI genutzt, um Siri zu verbessern oder Bilder zu schärfen. In der Datenschutzrichtlinie von Apple heißt es: „Apple trifft keine "
#~ "Entscheidungen, die die Verwendung von Algorithmen oder die Erstellung von Profilen beinhalten, die Sie erheblich beeinträchtigen.“ Hier finden Sie Teile der Forschung des Unternehmens: "
#~ "https://machinelearning.apple.com/"

#~ msgctxt "price"
#~ msgid "159 - $249"
#~ msgstr "159 - $249"
