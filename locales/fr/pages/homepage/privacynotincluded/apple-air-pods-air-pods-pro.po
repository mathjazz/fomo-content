#
msgid ""
msgstr ""
"POT-Creation-Date: 2021-07-15 08:21:36.403800+00:00\n"
"PO-Revision-Date: 2021-09-16 19:53+0000\n"
"Last-Translator: Théo Chevalier <theo.chevalier11@gmail.com>\n"
"Language: fr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 9e8ee13e-4d77-427a-819e-63d34b45e502\n"

msgctxt "title"
msgid "Apple Air Pods &amp; Air Pods Pro"
msgstr "Apple Air Pods et Air Pods Pro"

msgctxt "blurb"
msgid ""
"Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Whether you get the AirPods, AirPods Pro, or the"
" pricey AirPods Max, Apple has a pretty good record when it comes to privacy and security so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
msgstr ""

msgctxt "worst_case"
msgid ""
"Apple does a pretty good job with privacy and security as a company. They say they don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with "
"you, which is great. Apple did face backlash in 2019 when it came to light their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice "
"assistant's recordings. Apple changed their policy so users weren't automatically opted-in to human voice review. Recently, Apple made another <a id=\"a1\">positive change</a> for your Siri voice "
"requests — many audio requests for things like setting timers or alarms or controlling music will no longer be sent over the internet to their servers, instead processing them directly on the "
"device. This is better for your privacy."
msgstr ""

msgctxt "worst_case"
msgid ""
"Apple did recently suffer a bad <a id=\"a1\">security vulnerability</a> that resulted in spyware that could allow bad actors to record calls and messages and even turn an iPhone or iPad camera and "
"microphone on without the user knowing. Apple did patch the security vulnerability. This is a good reminder that even the best companies can be vulnerable to high level hacking."
msgstr ""

msgctxt "worst_case"
msgid ""
"All in all, your AirPods are probably pretty secure and private. They’re still super easy to lose though, so keep in mind you can turn the <a id=\"a1\">Find My</a> features on. That just means a "
"little more location tracking in your life, which, in this case might be worth it."
msgstr ""

msgctxt "signup_requirement_explanation"
msgid "No sign-up required"
msgstr ""

msgctxt "how_does_it_use_data_collected"
msgid ""
"Apple says it does not share your data with third parties for commercial or marketing purposes. In June 2021, Apple <a id=\"a1\">announced</a> that it will no longer send Siri requests to its "
"servers, but instead will process them at the device level."
msgstr ""

msgctxt "user_friendly_privacy_policy_helptext"
msgid ""
"Apple has a webpage highlighting its privacy principles and features. Apple begins its privacy policy with a statement of principles. While this statement is very long, it is clearly broken out into"
" relevant topics."
msgstr ""

msgctxt "strong_password_helptext"
msgid "Bluetooth required"
msgstr ""

msgctxt "manage_vulnerabilities_helptext"
msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. <a id=\"a1\">https://developer.apple.com/security-bounty/</a>"
msgstr ""

msgctxt "tips_to_protect_yourself"
msgid "You can say “Hey Siri, stop listening.” to turn off speech recognition for some time"
msgstr ""

msgctxt "personal_data_collected"
msgid "Name, email, phone number, address"
msgstr "Nom, adresse e-mail, numéro de téléphone, adresse postale"

msgctxt "biometric_data_collected"
msgid "Voice recordings, if you opt-in"
msgstr "Enregistrements vocaux si vous l’acceptez"

msgctxt "how_can_you_control_your_data"
msgid ""
"Apple retains personal data only for so long as necessary to fulfill the purposes for which it was collected, including as described in their Privacy Policy or in their service-specific privacy "
"notices, or as required by law. No specific data retention details are provided."
msgstr ""

msgctxt "track_record_details"
msgid ""
"Apple had a recent serious security vulnerability. From <a id=\"a1\">Firewall Times</a>: \"In September 2021, researchers discovered that a spyware called Pegasus had infected iPhones and other "
"Apple Devices via a ‘zero click exploit’, granting the spyware broad power over a users’ device. Once infected, the spyware could record calls and messages and even turn the device camera and "
"microphone on without the user knowing. Pegasus was produced by the NSO Group, an Israel-based company that sells its spyware to governments such as Mexico and Saudi Arabia. Though this spyware "
"would presumably be used to surveil terrorists and criminal enterprises, these governments have also used it to spy on activists, politicians, and journalists. As of September 13, 2021, Apple has "
"patched the exploit."
msgstr ""

msgctxt "ai_helptext"
msgid "Some of Apple's AI research can be found at <a id=\"a1\">https://machinelearning.apple.com/</a>."
msgstr ""

msgctxt "ai_what_can_it_do"
msgid ""
"Apple states in its privacy policy, \"Apple does not take any decisions involving the use of algorithms or profiling that significantly affect you.\" Apple employs machine learning in many different"
" ways, from using it to to improve Siri to using it to sharpen the photos that you take."
msgstr ""

#~ msgctxt "price"
#~ msgid "159 - $249"
#~ msgstr "159 - $249"

#~ msgctxt "worst_case"
#~ msgid ""
#~ "Apple does a good job with privacy and security as a company. They don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with you. Apple did "
#~ "face backlash in 2019 when it came to light that their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice assistant's recordings. Apple"
#~ " changed their policy so users weren't automatically opted-in to human voice review. Good work Apple!"
#~ msgstr ""
#~ "Apple fait plutôt du bon travail en matière de confidentialité et de sécurité. L’entreprise ne partage pas vos données et ne les vend pas, et Apple s’assure que vos demandes à Siri ne soient pas "
#~ "associées à vous. Apple a toutefois été très critiqué en 2019, quand il a été révélé que leurs contractuels écoutaient régulièrement des conversations personnelles lors de l’analyse des "
#~ "enregistrements de l’assistant vocal. Apple a modifié sa politique de confidentialité pour que le contrôle humain des enregistrements vocaux ne soit plus accepté par défaut. Bravo Apple !"

#~ msgctxt "how_does_it_use_data_collected"
#~ msgid ""
#~ "Apple does not share your data with third parties for commercial or marketing purposes. All of your Siri voice requests are associated to a random identifier, and if you have opted-in to allow Apple"
#~ " to have Voice recordings, Apple disassociates them after 6 months.  Apple does not share data with third parties for commercial or marketing purposes."
#~ msgstr ""
#~ "Apple ne partage pas vos données avec des tiers à des fins commerciales ou publicitaires. Toutes vos demandes vocales à Siri sont associées à un identifiant aléatoire et, si vous avez autorisé Apple"
#~ " à conserver les enregistrements vocaux, l’entreprise les dissocie de l’identifiant au bout de six mois. Apple ne partage pas de données avec des tiers à des fins commerciales ou publicitaires."

#~ msgctxt "uses_encryption_helptext"
#~ msgid ""
#~ "Uses encryption in transit and at rest. After Apple recognizes the words “Hey Siri,” what you say is encrypted and associated with a random identifier without being tied to your Apple ID. Audio "
#~ "samples are only retained if you have opted-in."
#~ msgstr ""
#~ "Utilisation du chiffrement en transit et au repos. Quand Apple reconnaît les mots « Dis Siri », ce que vous dites est chiffré et associé à un identifiant aléatoire sans lien avec votre identifiant "
#~ "Apple. Des extraits audio peuvent être conservés uniquement si vous l’avez accepté."

#~ msgctxt "strong_password_helptext"
#~ msgid "The device pairs securely via Bluetooth, which does not require a password."
#~ msgstr "L’appareil utilise un système de jumelage sécurisé par Bluetooth, qui ne nécessite pas de mot de passe."

#~ msgctxt "manage_vulnerabilities_helptext"
#~ msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. https://developer.apple.com/security-bounty/"
#~ msgstr ""
#~ "Apple dispose d’un programme de prime aux bogues (« bug bounty »), ce qui signifie que toute personne qui découvre une faille de sécurité et la signale de façon responsable peut être payée. "
#~ "https://developer.apple.com/security-bounty/"

#~ msgctxt "how_can_you_control_your_data"
#~ msgid "You can request that data be deleted. You can go to https://privacy.apple.com/ to get a copy of your data, correct your data, or delete your account."
#~ msgstr "Vous pouvez demander la suppression des données. Vous pouvez vous rendre sur https://privacy.apple.com/ pour obtenir une copie de vos données, les modifier ou supprimer votre compte."

#~ msgctxt "track_record_details"
#~ msgid ""
#~ "They actually changed their Siri voice recording review practices—from an opt out to an opt-in—when people told them they were unhappy having contractors listen to the recordings. Good for them!"
#~ msgstr ""
#~ "L’entreprise a modifié ses pratiques en matière de contrôle des enregistrements vocaux de Siri (passant d’une acceptation par défaut à un refus par défaut) quand les client·e·s ont exprimé leur "
#~ "mécontentement à l’idée que des contractuels écoutent leurs enregistrements. Bravo !"

#~ msgctxt "ai_helptext"
#~ msgid ""
#~ "Apple employs machine learning in many different ways, from using it to to improve Siri to using it to sharpen the photos that you take. Apple states in its privacy policy, \"Apple does not take any"
#~ " decisions involving the use of algorithms or profiling that significantly affect you.\" Some of its research can be found at https://machinelearning.apple.com/."
#~ msgstr ""
#~ "Apple utilise l’apprentissage automatique de nombreuses façons, par exemple pour améliorer Siri ou augmenter la netteté de vos photos. Dans sa politique de confidentialité, Apple déclare : « Apple "
#~ "ne prend aucune décision impliquant l’utilisation d’algorithmes ou de profilage susceptible de vous affecter de façon significative ». Vous pouvez consulter une partie des recherches de l’entreprise"
#~ " sur https://machinelearning.apple.com/."

#~ msgctxt "blurb"
#~ msgid ""
#~ "Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Fortunately, Apple has a pretty good record when"
#~ " it comes to privacy and security though so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
#~ msgstr ""
#~ "Des objets à mettre dans vos oreilles, qui sont toujours allumés, toujours connectés et toujours en train d’écouter… ça pourrait mal tourner. Heureusement, Apple a un historique plutôt solide en "
#~ "matière de confidentialité et de sécurité, donc vous devriez être à l’abri des problèmes. Assurez-vous juste de ne pas perdre ces précieuses petites oreillettes."
